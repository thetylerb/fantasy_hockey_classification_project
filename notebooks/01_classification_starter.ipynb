{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc648b3",
   "metadata": {},
   "source": [
    "\n",
    "# Fantasy Hockey Classification — Starter Notebook\n",
    "\n",
    "This notebook builds two **classification** models using your multi-year fantasy hockey data:\n",
    "\n",
    "1. **Skaters:** Predict whether a player will score **≥ 20 goals** (`is_20_goals`).\n",
    "2. **Goalies:** Predict whether a goalie will have a **save% above the seasonal median** (`is_above_median_sv`).\n",
    "\n",
    "We'll cover: loading, cleaning (including **deduplication**), EDA, feature engineering, model training, evaluation, and insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9da091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             ConfusionMatrixDisplay, RocCurveDisplay)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df90206b",
   "metadata": {},
   "source": [
    "## Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1421a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATHS = {\n",
    "    \"skaters\": [\n",
    "        \"/mnt/data/22_23_player_stats.csv\",\n",
    "        \"/mnt/data/23_24_player_stats.csv\",\n",
    "        \"/mnt/data/24_25_player_stats.csv\",\n",
    "        \"/mnt/data/skaters_combined_3yr.csv\",  # optional merged\n",
    "    ],\n",
    "    \"goalies\": [\n",
    "        \"/mnt/data/22_23_goalie_stats.csv\",\n",
    "        \"/mnt/data/23_24_goalie_stats.csv\",\n",
    "        \"/mnt/data/24_25_goalie_stats.csv\",\n",
    "        \"/mnt/data/goalies_combined_3yr.csv\", # optional merged\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Verify available files\n",
    "for group, paths in DATA_PATHS.items():\n",
    "    print(f\"\\n{group.upper()}\")\n",
    "    for p in paths:\n",
    "        print(\"  exists:\", os.path.exists(p), p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2039a9f",
   "metadata": {},
   "source": [
    "## Load & combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ad272",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_concat(paths):\n",
    "    frames = []\n",
    "    for p in paths:\n",
    "        if os.path.exists(p):\n",
    "            df = pd.read_csv(p)\n",
    "            df[\"source_file\"] = Path(p).name\n",
    "            frames.append(df)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No data files found. Check DATA_PATHS above.\")\n",
    "    return pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "skaters_raw = load_concat(DATA_PATHS[\"skaters\"])\n",
    "goalies_raw = load_concat(DATA_PATHS[\"goalies\"])\n",
    "\n",
    "print(\"Skaters shape:\", skaters_raw.shape)\n",
    "print(\"Goalies shape:\", goalies_raw.shape)\n",
    "skaters_raw.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62eacd",
   "metadata": {},
   "source": [
    "## Basic cleaning & deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45754655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_standardize(df, id_cols_guess=(\"Player\",\"player\",\"Name\",\"name\"), team_cols=(\"Team\",\"team\"), pos_cols=(\"Pos\",\"Position\",\"position\")):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Trim strings\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Standardize team & position if present\n",
    "    for t in team_cols:\n",
    "        if t in df.columns:\n",
    "            df[t] = df[t].str.upper()\n",
    "\n",
    "    for p in pos_cols:\n",
    "        if p in df.columns:\n",
    "            df[p] = df[p].str.upper().str.replace(\"C/LW\",\"C-LW\").str.replace(\"LW/C\",\"LW-C\")\n",
    "\n",
    "    # Remove exact duplicate rows\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    after = len(df)\n",
    "    print(f\"Exact duplicate rows removed: {before - after}\")\n",
    "\n",
    "    # If we have an obvious ID + season, dedup by that\n",
    "    season_cols = [c for c in df.columns if \"season\" in c.lower() or c.lower() in {\"season\",\"year\"}]\n",
    "    id_col = next((c for c in id_cols_guess if c in df.columns), None)\n",
    "\n",
    "    if id_col is not None and season_cols:\n",
    "        key_cols = [id_col] + season_cols\n",
    "        before = len(df)\n",
    "        df = df.sort_index().drop_duplicates(subset=key_cols, keep=\"first\")\n",
    "        after = len(df)\n",
    "        print(f\"Per-ID-per-season duplicates removed: {before - after}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "skaters = clean_standardize(skaters_raw)\n",
    "goalies = clean_standardize(goalies_raw)\n",
    "skaters.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c64c0",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(skaters.describe(include='all').T.head(20))\n",
    "display(goalies.describe(include='all').T.head(20))\n",
    "\n",
    "# If goal columns exist, visualize distribution\n",
    "for gcol in [\"G\",\"Goals\",\"goals\"]:\n",
    "    if gcol in skaters.columns:\n",
    "        fig = px.histogram(skaters, x=gcol, nbins=30, title=f\"Skater {gcol} distribution\")\n",
    "        fig.show()\n",
    "        break\n",
    "\n",
    "# Save EDA figures (Matplotlib example)\n",
    "plt.figure()\n",
    "numeric_cols = skaters.select_dtypes(include=np.number).columns[:10]\n",
    "skaters[numeric_cols].corr(numeric_only=True).abs().stack().nlargest(1)\n",
    "plt.title(\"Placeholder Figure\")\n",
    "plt.savefig(\"../figures/placeholder.png\", bbox_inches=\"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4399f4",
   "metadata": {},
   "source": [
    "## Skater classification target: `is_20_goals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da50afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GOAL_COL = next((c for c in [\"G\",\"Goals\",\"goals\"] if c in skaters.columns), None)\n",
    "if GOAL_COL is None:\n",
    "    raise ValueError(\"Could not find goals column in skater data (expected one of G/Goals/goals).\")\n",
    "\n",
    "skaters = skaters.copy()\n",
    "skaters[\"is_20_goals\"] = (skaters[GOAL_COL] >= 20).astype(int)\n",
    "print(skaters[\"is_20_goals\"].value_counts())\n",
    "skaters[[\"is_20_goals\", GOAL_COL]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08adb905",
   "metadata": {},
   "source": [
    "### Select feature columns for skater model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd75cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Heuristic: choose common numeric performance columns if present\n",
    "candidate_num = [c for c in [\"G\",\"A\",\"P\",\"S\",\"SOG\",\"TOI\",\"TOI/S\",\"CF\",\"xG\",\"iCF\",\"iHDCF\",\"PP TOI\",\"SH TOI\",\"Hits\",\"Blocks\",\"PIM\",\"FO%\",\"SH%\"] if c in skaters.columns]\n",
    "candidate_cat = [c for c in [\"Team\",\"Pos\",\"Position\",\"playerTeam\",\"TeamName\"] if c in skaters.columns]\n",
    "\n",
    "features_skaters_num = candidate_num\n",
    "features_skaters_cat = candidate_cat\n",
    "\n",
    "print(\"Numeric features:\", features_skaters_num)\n",
    "print(\"Categorical features:\", features_skaters_cat)\n",
    "\n",
    "model_df = skaters.dropna(subset=[GOAL_COL]).copy()\n",
    "X_num = features_skaters_num\n",
    "X_cat = features_skaters_cat\n",
    "y = model_df[\"is_20_goals\"]\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), X_num),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), X_cat)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=200),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
    "    \"SVM\": SVC(probability=True, kernel=\"rbf\"),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "}\n",
    "\n",
    "X = model_df[X_num + X_cat]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "results_skaters = []\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe, \"predict_proba\") else None\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    if y_proba is not None and len(np.unique(y_test)) == 2:\n",
    "        try:\n",
    "            metrics[\"roc_auc\"] = roc_auc_score(y_test, y_proba)\n",
    "        except Exception:\n",
    "            metrics[\"roc_auc\"] = np.nan\n",
    "    results_skaters.append(metrics)\n",
    "\n",
    "pd.DataFrame(results_skaters).sort_values(\"f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_name = max(results_skaters, key=lambda m: m[\"f1\"])[\"model\"]\n",
    "best_pipe = Pipeline(steps=[(\"prep\", preprocess), (\"clf\", models[best_name])])\n",
    "best_pipe.fit(X_train, y_train)\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_pipe, X_test, y_test)\n",
    "plt.title(f\"Skaters: Confusion Matrix ({best_name})\")\n",
    "plt.show()\n",
    "\n",
    "if hasattr(best_pipe, \"predict_proba\"):\n",
    "    RocCurveDisplay.from_estimator(best_pipe, X_test, y_test)\n",
    "    plt.title(f\"Skaters: ROC Curve ({best_name})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa0f5cf",
   "metadata": {},
   "source": [
    "## Goalie classification target: `is_above_median_sv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d02b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to find save percentage and games played columns\n",
    "SV_COL = next((c for c in [\"SV%\", \"Sv%\", \"SVPCT\", \"Save%\", \"save_percentage\", \"sv%\"] if c in goalies.columns), None)\n",
    "GP_COL = next((c for c in [\"GP\",\"Games\",\"games_played\"] if c in goalies.columns), None)\n",
    "\n",
    "if SV_COL is None:\n",
    "    # try to compute SV% if S and SA exist\n",
    "    if all(c in goalies.columns for c in [\"Saves\",\"ShotsAgainst\"]):\n",
    "        goalies[\"SV_computed\"] = goalies[\"Saves\"] / goalies[\"ShotsAgainst\"]\n",
    "        SV_COL = \"SV_computed\"\n",
    "    else:\n",
    "        raise ValueError(\"Could not find save% column in goalie data (expected SV%/variants or Saves & ShotsAgainst).\")\n",
    "\n",
    "# Filter out small samples (e.g., fewer than 10 games) if GP available\n",
    "gdf = goalies.copy()\n",
    "if GP_COL is not None:\n",
    "    gdf = gdf[gdf[GP_COL] >= 10].copy()\n",
    "\n",
    "median_sv = gdf[SV_COL].median()\n",
    "gdf[\"is_above_median_sv\"] = (gdf[SV_COL] >= median_sv).astype(int)\n",
    "print(\"Median SV:\", median_sv)\n",
    "print(gdf[\"is_above_median_sv\"].value_counts())\n",
    "gdf[[SV_COL, \"is_above_median_sv\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e532b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "candidate_num_g = [c for c in [\"SV%\",\"SVPCT\",\"GAA\",\"GSAA\",\"QS%\",\"RBS\",\"SO\",\"Wins\",\"Losses\",\"ShotsAgainst\",\"Saves\",\"TOI\"] if c in gdf.columns]\n",
    "candidate_cat_g = [c for c in [\"Team\",\"team\"] if c in gdf.columns]\n",
    "\n",
    "features_goalies_num = candidate_num_g\n",
    "features_goalies_cat = candidate_cat_g\n",
    "print(\"Numeric features (goalies):\", features_goalies_num)\n",
    "print(\"Categorical features (goalies):\", features_goalies_cat)\n",
    "\n",
    "y_g = gdf[\"is_above_median_sv\"]\n",
    "X_g = gdf[features_goalies_num + features_goalies_cat]\n",
    "\n",
    "preprocess_g = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), features_goalies_num),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), features_goalies_cat)\n",
    "])\n",
    "\n",
    "models_g = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=200),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SVM\": SVC(probability=True, kernel=\"rbf\"),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "}\n",
    "\n",
    "Xg_train, Xg_test, yg_train, yg_test = train_test_split(X_g, y_g, test_size=0.25, random_state=42, stratify=y_g)\n",
    "\n",
    "results_goalies = []\n",
    "for name, clf in models_g.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess_g), (\"clf\", clf)])\n",
    "    pipe.fit(Xg_train, yg_train)\n",
    "    yg_pred = pipe.predict(Xg_test)\n",
    "    yg_proba = pipe.predict_proba(Xg_test)[:,1] if hasattr(pipe, \"predict_proba\") else None\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(yg_test, yg_pred),\n",
    "        \"precision\": precision_score(yg_test, yg_pred, zero_division=0),\n",
    "        \"recall\": recall_score(yg_test, yg_pred, zero_division=0),\n",
    "        \"f1\": f1_score(yg_test, yg_pred, zero_division=0),\n",
    "    }\n",
    "    if yg_proba is not None and len(np.unique(yg_test)) == 2:\n",
    "        try:\n",
    "            metrics[\"roc_auc\"] = roc_auc_score(yg_test, yg_proba)\n",
    "        except Exception:\n",
    "            metrics[\"roc_auc\"] = np.nan\n",
    "    results_goalies.append(metrics)\n",
    "\n",
    "pd.DataFrame(results_goalies).sort_values(\"f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a49cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_name_g = max(results_goalies, key=lambda m: m[\"f1\"])[\"model\"]\n",
    "best_pipe_g = Pipeline(steps=[(\"prep\", preprocess_g), (\"clf\", models_g[best_name_g])])\n",
    "best_pipe_g.fit(Xg_train, yg_train)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(best_pipe_g, Xg_test, yg_test)\n",
    "plt.title(f\"Goalies: Confusion Matrix ({best_name_g})\")\n",
    "plt.show()\n",
    "\n",
    "if hasattr(best_pipe_g, \"predict_proba\"):\n",
    "    RocCurveDisplay.from_estimator(best_pipe_g, Xg_test, yg_test)\n",
    "    plt.title(f\"Goalies: ROC Curve ({best_name_g})\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764fd1f",
   "metadata": {},
   "source": [
    "\n",
    "## Notes & Next Steps\n",
    "\n",
    "- Tune hyperparameters (GridSearchCV / RandomizedSearchCV).\n",
    "- Address any **class imbalance** (try class weights or resampling).\n",
    "- Cross-validate and add **confidence intervals** on metrics.\n",
    "- Expand features (rolling rates, 5v5 vs PP, usage/linemates, venue effects).\n",
    "- Export best model & pipeline for deployment.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
